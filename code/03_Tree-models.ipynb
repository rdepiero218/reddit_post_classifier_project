{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & NLP\n",
    "## *Template Notebook*\n",
    "\n",
    "In this notebook:\n",
    "\n",
    "* [Basic Decision Tree](#basic)\n",
    "* [Bagged Decision Tree](#bagged)\n",
    "* [Random Forest](#random)\n",
    "* [Best Model](#best-model)\n",
    "\n",
    "#### Import Libraries & Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard imports \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "## visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "## modeling\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "## trees\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier, ExtraTreesClassifier, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor\n",
    "## NLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "## analysis\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, make_scorer, f1_score, mean_squared_error\n",
    "\n",
    "## options\n",
    "import sklearn\n",
    "pd.options.display.max_rows = 4000\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in data\n",
    "data = pd.read_csv('../data/reddit_posts_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select data\n",
    "X = data['selftext']\n",
    "y = data['is_fallout']\n",
    "### TTS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Decision Tree <a class=\"anchor\" id=\"basic\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = make_pipeline(CountVectorizer(stop_words='english', max_features=100), DecisionTreeClassifier())\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print('Training Score: ', dt.score(X_train, y_train))\n",
    "print('Testing Score: ', dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a baseline for our decision tree model performance. Let's see if we can improve things by selecting more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.9769253380364491\n",
      "Testing Score:  0.8871252204585538\n",
      "Best Parameters:  {'countvectorizer__max_features': 800}\n"
     ]
    }
   ],
   "source": [
    "dt = make_pipeline(CountVectorizer(stop_words='english'), DecisionTreeClassifier())\n",
    "\n",
    "params = {\n",
    "    'countvectorizer__max_features' : [100, 500, 800],\n",
    "\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(dt, param_grid = params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Training Score: ', grid.score(X_train, y_train))\n",
    "print('Testing Score: ', grid.score(X_test, y_test))\n",
    "print('Best Parameters: ', grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses max option for features so let's see what happens when we use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.987801293356849\n",
      "Testing Score:  0.8849206349206349\n"
     ]
    }
   ],
   "source": [
    "dt = make_pipeline(CountVectorizer(stop_words='english'), DecisionTreeClassifier())\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print('Training Score: ', dt.score(X_train, y_train))\n",
    "print('Testing Score: ', dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance isn't improved that much but we'll use the entire data set for subsequent tree models as long as computing performance is ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged Decision Tree <a class=\"anchor\" id=\"bagged\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.9847148736037625\n",
      "Testing Score:  0.8990299823633157\n"
     ]
    }
   ],
   "source": [
    "bag = make_pipeline(CountVectorizer(stop_words='english'), BaggingClassifier()) \n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "print('Training Score: ', bag.score(X_train, y_train))\n",
    "print('Testing Score: ', bag.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Training Score:  0.9840441853329243\n",
      "F1 Testing Score:  0.8972633467922836\n"
     ]
    }
   ],
   "source": [
    "print('F1 Training Score: ', f1_score(y_train, bag.predict(X_train)))\n",
    "print('F1 Testing Score: ', f1_score(y_test, bag.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging doesn't seem to improve the decision tree performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest <a class=\"anchor\" id=\"random\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.987801293356849\n",
      "Testing Score:  0.9223985890652557\n"
     ]
    }
   ],
   "source": [
    "rfc = make_pipeline(CountVectorizer(stop_words='english'), RandomForestClassifier())\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training Score: ', rfc.score(X_train, y_train))\n",
    "print('Testing Score: ', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. This one is pretty good considering I'm doing nothing special to this thing at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Training Score:  0.9872796934865901\n",
      "F1 Testing Score:  0.921146953405018\n"
     ]
    }
   ],
   "source": [
    "print('F1 Training Score: ', f1_score(y_train, rfc.predict(X_train)))\n",
    "print('F1 Testing Score: ', f1_score(y_test, rfc.predict(X_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Testing Score:  0.9704236610711432\n"
     ]
    }
   ],
   "source": [
    "y_preds = rfc.predict(X)\n",
    "print('F1 Score: ', f1_score(y, y_preds) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has the least evidence of overfitting and performs pretty well compared to basic models explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model <a class=\"anchor\" id=\"best-model\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Training Score:  0.987801293356849\n",
      "R2 Testing Score:  0.9232804232804233\n",
      "-----------------------\n",
      "F1 Training Score:  0.9872796934865901\n",
      "F1 Testing Score:  0.9222520107238605\n",
      "-----------------------\n",
      "Complete F1 Score:  0.9706721442428392\n"
     ]
    }
   ],
   "source": [
    "rfc = make_pipeline(CountVectorizer(stop_words='english'), RandomForestClassifier())\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "print('R2 Training Score: ', rfc.score(X_train, y_train))\n",
    "print('R2 Testing Score: ', rfc.score(X_test, y_test))\n",
    "print('-----------------------')\n",
    "print('F1 Training Score: ', f1_score(y_train, rfc.predict(X_train)))\n",
    "print('F1 Testing Score: ', f1_score(y_test, rfc.predict(X_test))) \n",
    "print('-----------------------')\n",
    "y_preds = rfc.predict(X)\n",
    "print('Complete F1 Score: ', f1_score(y, y_preds) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

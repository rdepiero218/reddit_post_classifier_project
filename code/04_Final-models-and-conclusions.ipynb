{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & NLP\n",
    "## *Final Models & Conclusions*\n",
    "\n",
    "The final two models are presented along with conclusions and futher explorations that could be conducted.\n",
    "\n",
    "In this notebook:\n",
    "\n",
    "* [Naive Bayes](#nb-model)\n",
    "* [Random Forest](#rf-model)\n",
    "* [Conclusions](#conclusions)\n",
    "* [Further Exploration](#further)\n",
    "\n",
    "#### Import Libraries & Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard imports \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "## visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "## modeling\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "## trees\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier, ExtraTreesClassifier, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, AdaBoostClassifier, GradientBoostingRegressor\n",
    "## NLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "## analysis\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, make_scorer, f1_score, mean_squared_error\n",
    "\n",
    "## options\n",
    "import sklearn\n",
    "pd.options.display.max_rows = 4000\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in data\n",
    "data = pd.read_csv('../data/reddit_posts_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select data\n",
    "X = data['selftext']\n",
    "y = data['is_fallout']\n",
    "### TTS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model <a class=\"anchor\" id=\"nb-model\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Training Score:  0.9610523221634333\n",
      "R2 Testing Score:  0.9444444444444444\n",
      "-----------------------\n",
      "F1 Score training:  0.9581292463264338\n",
      "F1 Score testing:  0.9405099150141643\n",
      "-----------------------\n",
      "Complete F1 Score:  0.9537113768201729\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(CountVectorizer(stop_words='english'),  MultinomialNB())\n",
    "\n",
    "params = {\n",
    "    'countvectorizer__min_df': [2],\n",
    "    'countvectorizer__max_df': [0.9],\n",
    "    'countvectorizer__ngram_range': [(1, 1)],\n",
    "    'multinomialnb__alpha': [0.0001]         \n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('R2 Training Score: ', grid.score(X_train, y_train))\n",
    "print('R2 Testing Score: ', grid.score(X_test, y_test))\n",
    "print('-----------------------')\n",
    "print('F1 Score training: ', f1_score(y_train, grid.predict(X_train)))\n",
    "print('F1 Score testing: ', f1_score(y_test, grid.predict(X_test)))\n",
    "y_preds = grid.predict(X)\n",
    "print('-----------------------')\n",
    "print('Complete F1 Score: ', f1_score(y, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model <a class=\"anchor\" id=\"rf-model\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Training Score:  0.987801293356849\n",
      "R2 Testing Score:  0.9206349206349206\n",
      "-----------------------\n",
      "F1 Training Score:  0.9872835912364026\n",
      "F1 Testing Score:  0.9192825112107623\n",
      "-----------------------\n",
      "Complete F1 Score:  0.9699668836359484\n"
     ]
    }
   ],
   "source": [
    "rfc = make_pipeline(CountVectorizer(stop_words='english'), RandomForestClassifier())\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "print('R2 Training Score: ', rfc.score(X_train, y_train))\n",
    "print('R2 Testing Score: ', rfc.score(X_test, y_test))\n",
    "print('-----------------------')\n",
    "print('F1 Training Score: ', f1_score(y_train, rfc.predict(X_train)))\n",
    "print('F1 Testing Score: ', f1_score(y_test, rfc.predict(X_test))) \n",
    "print('-----------------------')\n",
    "y_preds = rfc.predict(X)\n",
    "print('Complete F1 Score: ', f1_score(y, y_preds) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions <a class=\"anchor\" id=\"conclusions\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increasing n-grams did not improve model performance.\n",
    "* Use of TfidfVectorizer did not improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exploration <a class=\"anchor\" id=\"further\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Further processing of data could be done to clean text.\n",
    "* Additional stop words could be added.\n",
    "* Use of lemmatizing/stemming\n",
    "* Further analysis of words specific to each subreddit. Is there a better way to choose words outside of count?\n",
    "* Further exploration of parameter selection in tree models to attempt to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
